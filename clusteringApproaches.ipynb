{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "4CXS_-z35EuV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptZVRMWXvBNe",
        "outputId": "308ca68c-e2cc-44b9-83dd-1fd65b3709df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [1 2 2 0 2 0 0 0 1 1 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "data = [65, 22, 25, 42, 28, 43, 33, 35, 56, 61, 18]\n",
        "k = 3  # Number of clusters\n",
        "\n",
        "model = AgglomerativeClustering(n_clusters=k, linkage='ward')  # You can choose different linkage types\n",
        "clusters = model.fit_predict(np.array(data).reshape(-1, 1))\n",
        "\n",
        "print(\"Cluster labels:\", clusters)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[65], [22], [25], [42], [28], [43], [33], [35], [56], [61], [18]])\n",
        "\n",
        "# Parameters for DBSCAN\n",
        "epsilon = 10  # The maximum distance between two samples to be considered in the same neighborhood\n",
        "min_samples = 2  # Minimum number of samples in a neighborhood for a point to be considered as a core point\n",
        "\n",
        "# Create DBSCAN object and fit the data\n",
        "dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
        "clusters = dbscan.fit_predict(data)\n",
        "\n",
        "print(\"Cluster labels:\", clusters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abYgLY168CyM",
        "outputId": "79fb5db5-26f9-4bcd-ebf1-b7f1d518fb84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [0 1 1 1 1 1 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(a, b):\n",
        "    return np.linalg.norm(a - b)\n",
        "\n",
        "def dbscan_manual(data, epsilon, min_samples):\n",
        "    labels = [0] * len(data)  # Initial label for each point\n",
        "\n",
        "    cluster_id = 0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if labels[i] != 0:  # Skip points that are already visited or assigned to a cluster\n",
        "            continue\n",
        "\n",
        "        neighbors = []  # List to hold the indexes of neighboring points\n",
        "\n",
        "        for j in range(len(data)):\n",
        "            if euclidean_distance(data[i], data[j]) < epsilon:\n",
        "                neighbors.append(j)\n",
        "\n",
        "        if len(neighbors) < min_samples:\n",
        "            labels[i] = -1  # Mark as noise point\n",
        "        else:\n",
        "            cluster_id += 1\n",
        "            labels[i] = cluster_id  # Assign a new cluster ID\n",
        "\n",
        "            for j in neighbors:\n",
        "                if labels[j] == -1:  # Change noise points to border points\n",
        "                    labels[j] = cluster_id\n",
        "                elif labels[j] == 0:  # Points not yet visited\n",
        "                    labels[j] = cluster_id\n",
        "                    new_neighbors = []\n",
        "\n",
        "                    for k in range(len(data)):\n",
        "                        if euclidean_distance(data[j], data[k]) < epsilon:\n",
        "                            new_neighbors.append(k)\n",
        "\n",
        "                    if len(new_neighbors) >= min_samples:\n",
        "                        neighbors.extend(new_neighbors)\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[65], [22], [25], [42], [28], [43], [33], [35], [56], [61], [18]])\n",
        "\n",
        "# Parameters for DBSCAN\n",
        "epsilon = 10  # The maximum distance between two samples to be considered in the same neighborhood\n",
        "min_samples = 2  # Minimum number of samples in a neighborhood for a point to be considered as a core point\n",
        "\n",
        "# Perform DBSCAN manually\n",
        "result_labels = dbscan_manual(data, epsilon, min_samples)\n",
        "print(\"Cluster labels:\", result_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjR6Tfl_9ARr",
        "outputId": "c3e74b0b-461c-4a94-9064-b5317bfd7780"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def grid_based_clustering(data, grid_size):\n",
        "    # Calculate the grid boundaries\n",
        "    min_vals = np.min(data, axis=0)\n",
        "    max_vals = np.max(data, axis=0)\n",
        "    num_cells = ((max_vals - min_vals) / grid_size).astype(int) + 1\n",
        "\n",
        "    # Create a grid structure\n",
        "    grid = np.zeros(num_cells, dtype=int)\n",
        "\n",
        "    # Assign points to grid cells\n",
        "    for point in data:\n",
        "        indices = ((point - min_vals) / grid_size).astype(int)\n",
        "        grid[tuple(indices)] += 1  # Increment cell count\n",
        "\n",
        "    # Identify clusters based on cell density\n",
        "    clusters = []\n",
        "    for i in range(num_cells[0]):\n",
        "        for j in range(num_cells[1]):\n",
        "            if grid[i, j] > 0:\n",
        "                clusters.append((i, j))  # Store grid cells with density as clusters\n",
        "\n",
        "    return clusters\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [2, 1], [8, 9], [9, 8], [15, 17], [16, 18]])\n",
        "\n",
        "# Define grid size\n",
        "grid_size = np.array([5, 5])  # Adjust grid size as needed\n",
        "\n",
        "# Perform grid-based clustering\n",
        "result_clusters = grid_based_clustering(data, grid_size)\n",
        "print(\"Clusters based on grid cells:\", result_clusters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2KO_HyjFFYw",
        "outputId": "16b5729d-6367-436f-e74c-72e838ee5a89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters based on grid cells: [(0, 0), (1, 1), (2, 3), (3, 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [2, 1], [8, 9], [9, 8], [15, 17], [16, 18]])\n",
        "\n",
        "# Number of clusters\n",
        "num_clusters = 2\n",
        "\n",
        "# Fit Gaussian Mixture Model\n",
        "gmm = GaussianMixture(n_components=num_clusters, random_state=42)\n",
        "gmm.fit(data)\n",
        "\n",
        "# Predict cluster labels\n",
        "cluster_labels = gmm.predict(data)\n",
        "\n",
        "print(\"Cluster labels:\", cluster_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jorHQaP5JAwn",
        "outputId": "7099f163-549e-4549-8c6b-2b42fb477465"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [0 0 0 0 1 1]\n"
          ]
        }
      ]
    }
  ]
}